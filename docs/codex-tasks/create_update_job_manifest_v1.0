TARGET_SCRIPT: jobs/vendor_input_processing/matching_proposals/glue_script.py

TASK TYPE: Generate/Refresh job_manifest.yaml (Usable, low-TBD, evidence-based)

GOAL
Create or update the manifest located next to TARGET_SCRIPT:
- jobs/vendor_input_processing/matching_proposals/job_manifest.yaml

PHASE RULE
Phase 1 documentation only: describe WHAT EXISTS. No refactoring. No behavior changes.

ALLOWED SOURCES (ONLY)
1) TARGET_SCRIPT (including helper functions defined inside the same file)

HARD CONSTRAINTS
- Do NOT modify TARGET_SCRIPT.
- Do NOT modify any other file.
- Do NOT guess. If something cannot be proven from TARGET_SCRIPT, write "TBD".
- BUT: If something IS provable from TARGET_SCRIPT, you MUST populate it (TBD is not allowed in that case).

MANIFEST SCHEMA (MUST MATCH EXACTLY; keep this key order)
job_id: <parent folder name of TARGET_SCRIPT>
glue_job_name: TBD
runtime: TBD
entrypoint: glue_script.py

parameters:
  - TBD

inputs:
  - bucket: TBD
    key_pattern: TBD
    format: TBD
    required: TBD

outputs:
  - bucket: TBD
    key_pattern: TBD
    format: TBD
    required: TBD

config_files:
  - repo_path: TBD
    s3_bucket: TBD
    s3_key_pattern: TBD
    required: TBD

side_effects:
  deletes_inputs: TBD
  overwrites_outputs: TBD

logging_and_receipt:
  writes_run_receipt: TBD
  run_receipt_bucket: TBD
  run_receipt_key_pattern: TBD
  counters_observed:
    - TBD

notes:
  - "Phase 1 reverse-documentation: derived only from TARGET_SCRIPT; unknowns are marked TBD."
  - "TBD_EXPLANATIONS: (auto-filled list below)"

EXTRACTION REQUIREMENTS (THIS IS THE CORE)
A) Identify runtime parameters
- Extract the full, exact parameter list from the script’s argument parsing (e.g., getResolvedOptions(...) or argparse).
- Populate parameters with the exact names and casing, in the same order as in the code.
- If no explicit parameter parsing exists, leave parameters as TBD (and explain why in TBD_EXPLANATIONS).

B) Determine runtime (must not be TBD if decidable)
- If the script instantiates/uses SparkContext/SparkSession/GlueContext OR reads/writes via spark.* then runtime=pyspark.
- If it is plain Python without Spark/GlueContext usage then runtime=python_shell.
- Otherwise runtime=TBD and explain.

C) Enumerate ALL outputs (must not miss any)
You MUST enumerate every output that the script can write to S3 on a successful run, including outputs written through helper functions defined in the same file.

Output discovery rule:
- Treat as an "output write" any call (direct or via helper) that results in:
  - boto3 S3 put_object/copy_object/upload_file, OR
  - Spark write/save to an s3://... path, OR
  - any helper function that wraps one of the above.

For each distinct final artifact the script writes:
- Add an outputs[] entry with:
  - bucket: ${OUTPUT_BUCKET} or ${INPUT_BUCKET} if the bucket is derived from those params; otherwise a literal if hardcoded; otherwise TBD.
  - key_pattern: a parameterized pattern representing the final key (use ${param} placeholders only for params that actually exist in parameters list).
  - format: set only if the script explicitly makes it unambiguous; else TBD.
  - required: must be decided from control flow (see section E).

IMPORTANT:
- If the script writes 2 different final keys, outputs[] MUST contain 2 entries. Do not collapse.

D) Enumerate inputs
Identify the primary input artifact(s) the job consumes.
- If the script constructs or searches S3 keys/prefixes, capture the best representable key_pattern.
- bucket must use ${INPUT_BUCKET} when derived from that param.
- format: set only if the script explicitly constrains it; else TBD.
- required: must be decided from control flow (see section E).

E) Decide required=true/false (must not be TBD if decidable)
For each input and output, determine requiredness from explicit behavior:

Inputs:
- required=true if the script explicitly raises/exits with error when input is missing.
- required=false if the script explicitly handles missing input (e.g., writes empty output / logs and returns success).
- required=TBD only if neither behavior is provable.

Outputs:
- required=true if the script writes this output on ALL successful exit paths (including early-success exits that write empty {} / empty array).
- required=false if there exists any successful path where the job completes without writing this output.
- required=TBD only if you cannot prove either from code.

F) Decide side_effects booleans (must not be TBD if decidable)
- deletes_inputs:
  - true only if the script deletes objects in the input bucket/prefix.
  - false if all delete operations target output/temp areas only, and no deletes target inputs.
  - TBD only if deletion target cannot be determined.
- overwrites_outputs:
  - true if the script writes/copies to a deterministic final key (same key reused across runs) OR explicitly overwrites.
  - false if final output keys are always unique per run AND no overwrite is performed.
  - TBD only if not provable.

G) Decide writes_run_receipt (must not be TBD)
- If the script writes a dedicated receipt-like artifact (explicit key/variable/filename indicating receipt), set true and fill run_receipt_* if determinable.
- If there is no receipt-writing behavior in the script, set writes_run_receipt=false and set run_receipt_bucket/key_pattern to TBD.

H) config_files.required must not be TBD if decidable
- If the script reads a config file from S3, set config_files[0].required=true and populate bucket/key_pattern if determinable.
- If the script does not read any config file, set config_files[0].required=false (leave other config fields TBD).

TBD_EXPLANATIONS REQUIREMENT (MAKE TBDs USABLE)
At the bottom of notes, append a bullet list where each item is:
- "<field_path>: TBD — <why not provable from TARGET_SCRIPT>"

Example field_path formats:
- "glue_job_name"
- "inputs[0].format"
- "logging_and_receipt.counters_observed"

QUALITY GATES (MUST)
1) outputs[] must include every distinct final output key written by the job (including via helpers).
2) required fields must not be TBD when code makes them decidable.
3) writes_run_receipt must be true or false (never TBD).
4) side_effects booleans must not be TBD when code makes them decidable.
5) The manifest must remain fully within Phase 1 scope.

PR REQUIREMENTS
- Create a PR that changes ONLY:
  jobs/vendor_input_processing/matching_proposals/job_manifest.yaml

- PR description MUST include an "Evidence Map":
  For each non-TBD manifest field, list:
    field_path -> evidence pointer (function name / variable / literal key fragment / control-flow statement)
  For each TBD, confirm it appears in TBD_EXPLANATIONS.
