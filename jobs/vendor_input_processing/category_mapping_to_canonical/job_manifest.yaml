job_id: category_mapping_to_canonical
glue_job_name: ${JOB_NAME}
runtime: pyspark
entrypoint: glue_script.py

parameters:
  - JOB_NAME
  - INPUT_BUCKET
  - OUTPUT_BUCKET
  - vendor_name
  - preprocessed_input_key
  - prepared_output_prefix

inputs:
  - bucket: ${INPUT_BUCKET}
    key_pattern: ${preprocessed_input_key}${vendor_name}_vendor_products.json
    format: ndjson
    required: true
  - bucket: ${INPUT_BUCKET}
    key_pattern: ${preprocessed_input_key}${vendor_name}_product_category_links.json
    format: ndjson
    required: true
  - bucket: ${INPUT_BUCKET}
    key_pattern: ${preprocessed_input_key}${vendor_name}_vendor_categories.json
    format: ndjson
    required: true
  - bucket: ${INPUT_BUCKET}
    key_pattern: canonical_mappings/Category_Mapping_Reference_${timestamp}.json
    format: json
    required: false

outputs:
  - bucket: ${OUTPUT_BUCKET}
    key_pattern: ${prepared_output_prefix}/${vendor_name}_forMapping_products.ndjson
    format: ndjson
    required: true
  - bucket: ${OUTPUT_BUCKET}
    key_pattern: ${prepared_output_prefix}/${vendor_name}_forMapping_products
    format: ndjson
    required: true

side_effects:
  deletes_inputs: false
  overwrites_outputs: true

logging_and_receipt:
  writes_run_receipt: false
  run_receipt_bucket: TBD
  run_receipt_key_pattern: TBD
  counters_observed: TBD

notes:
  - "TBD_EXPLANATIONS:"
  - "logging_and_receipt.run_receipt_bucket: TBD — no run receipt S3 write is present in glue_script.py; bucket not applicable but spec requires explanation."
  - "logging_and_receipt.run_receipt_key_pattern: TBD — no run receipt S3 write is present in glue_script.py; key pattern not applicable but spec requires explanation."
  - "logging_and_receipt.counters_observed: TBD — script logs counts to stdout but does not persist a receipt with a defined counters schema."
