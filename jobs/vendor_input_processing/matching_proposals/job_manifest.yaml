job_id: matching_proposals
glue_job_name: ${JOB_NAME}
runtime: pyspark
entrypoint: glue_script.py
parameters:
  - JOB_NAME
  - INPUT_BUCKET
  - OUTPUT_BUCKET
  - vendor_name
  - prepared_input_key
  - prepared_output_prefix
inputs:
  - bucket: ${INPUT_BUCKET}
    key_pattern: ${prepared_input_key}/canonicalCategoryMapping/${vendor_name}_forMapping_products${optional_json_extension}
    format: json
    required: false
outputs:
  - bucket: ${OUTPUT_BUCKET}
    key_pattern: ${prepared_output_prefix}/${vendor_name}_categoryMatchingProposals.json
    format: json
    required: true
  - bucket: ${OUTPUT_BUCKET}
    key_pattern: ${prepared_output_prefix}/${vendor_name}_categoryMatchingProposals_oneVendor_to_onePim_match.json
    format: json
    required: false
side_effects:
  deletes_inputs: false
  overwrites_outputs: true
logging_and_receipt:
  writes_run_receipt: false
  run_receipt_bucket: TBD
  run_receipt_key_pattern: TBD
  counters_observed: TBD
notes:
  - TBD_EXPLANATIONS
  - logging_and_receipt.run_receipt_bucket is TBD because this script does not write a run receipt artifact to S3.
  - logging_and_receipt.run_receipt_key_pattern is TBD because this script does not write a run receipt artifact to S3.
  - logging_and_receipt.counters_observed is TBD because no run receipt counters are emitted in the script.
