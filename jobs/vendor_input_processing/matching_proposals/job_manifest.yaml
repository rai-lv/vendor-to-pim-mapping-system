schema_version: "1.0"
job_id: matching_proposals
glue_job_name: TBD
runtime: pyspark
entrypoint: glue_script.py

parameters:
  - JOB_NAME
  - INPUT_BUCKET
  - OUTPUT_BUCKET
  - vendor_name
  - prepared_input_key
  - prepared_output_prefix

inputs:
  - bucket: ${INPUT_BUCKET}
    key_pattern: ${prepared_input_key_norm}canonicalCategoryMapping/${vendor_name}_forMapping_products.json
    format: ndjson
    required: true

outputs:
  - bucket: ${OUTPUT_BUCKET}
    key_pattern: ${prepared_output_prefix_norm}${vendor_name}_categoryMatchingProposals.json
    format: json
    required: true
  - bucket: ${OUTPUT_BUCKET}
    key_pattern: ${prepared_output_prefix_norm}${vendor_name}_categoryMatchingProposals_oneVendor_to_onePim_match.json
    format: json
    required: true

side_effects:
  deletes_inputs: false
  overwrites_outputs: true

logging_and_receipt:
  writes_run_receipt: false
  run_receipt_bucket: TBD
  run_receipt_key_pattern: TBD
  counters_observed: TBD

notes:
  - "TBD_EXPLANATIONS:"
  - "glue_job_name: TBD — Not yet deployed to AWS Glue (no deployment config found in repo). Needs deployment config from DevOps team."
  - "logging_and_receipt.run_receipt_bucket: TBD — Script does not write a run receipt file to S3, only calls job.commit() for Glue bookkeeping (lines 165, 208, 221, 251, 352, 676 in glue_script.py)."
  - "logging_and_receipt.run_receipt_key_pattern: TBD — Script does not write a run receipt file to S3. See run_receipt_bucket explanation."
  - "logging_and_receipt.counters_observed: TBD — Script logs record counts to logger but does not emit structured counters to CloudWatch or a receipt file (e.g., lines 195-198, 229-234). Need to review CloudWatch metrics to identify emitted counters."
  - "Evidence source: Analyzed glue_script.py lines 1-710, checked getResolvedOptions (lines 24-34), S3 I/O patterns (lines 68-175, 689-705), Spark read.json (lines 183, 189), and write_json_dict_to_s3 helper (lines 689-705)."
  - "prepared_input_key normalization: Script normalizes prefix by rstrip('/') (line 68), so manifest uses ${prepared_input_key_norm} placeholder."
  - "prepared_output_prefix normalization: Script normalizes prefix by rstrip('/') (line 69), so manifest uses ${prepared_output_prefix_norm} placeholder."
  - "Input format: Script tries standard JSON read first (line 183), then multiLine=true as fallback (line 189). Primary read mode is line-delimited (ndjson), per Spark default behavior (see spec section 5.4.0.1)."
  - "Output format: Outputs are single JSON documents written via json.dumps with indent=2 (line 694), not line-delimited, so format is json."
